---
title: "Przedział ufności"
author: "Patrycja Głuch"
format: html
---

```{python}
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
```

1. Wczytanie danych z tabel zawierających informacje o średnich dziennych kursach wybranych walut udostępnianych przez Narodowy Bank Polski.

```{python}
# Wczytanie danych
url_2023 = 'https://static.nbp.pl/dane/kursy/Archiwum/archiwum_tab_a_2023.csv'
url_2024 = 'https://static.nbp.pl/dane/kursy/Archiwum/archiwum_tab_a_2024.csv'

# Tworzenie nagłówków z walutami
header_df_23 = pd.read_csv(url_2023, sep=';', decimal=',', nrows=0, encoding='latin1')
currency_columns_23 = header_df_23.columns[1:34] 
header_df_24 = pd.read_csv(url_2024, sep=';', decimal=',', nrows=0, encoding='latin1')
currency_columns_24 = header_df_24.columns[1:34]

# Wczytywanie danych ze zdefiniowanej liczby kolumn
df_23 = pd.read_csv(url_2023, sep=';', decimal=',', usecols=['data'] + list(currency_columns_23), encoding='latin1')
df_24 = pd.read_csv(url_2024, sep=';', decimal=',', usecols=['data'] + list(currency_columns_24), encoding='latin1')

# Usunięcie pierwszego wiersza danych
df_23 = df_23.drop(0)
df_24 = df_24.drop(0)

# Usunięcie ostatnich 3 wierszy
df_23 = df_23[:-3]
df_24 = df_24[:-3]

# Przekształcenie danych do formatu długiego
melted_df_23 = df_23.melt(id_vars=['data'], var_name='currency', value_name='value')
melted_df_24 = df_24.melt(id_vars=['data'], var_name='currency', value_name='value')

# Funkcja do rozdzielenia współczynnika wartości i kodu ISO
def split_number_from_chars(currency):
    match = re.match(r"(\d+)(\D+)", currency)
    if match:
        number, chars = match.groups()
        return int(number), chars
    return 1, currency 

# Zastosowanie powyższej funkcji
melted_df_23[['number', 'currency']] = melted_df_23['currency'].apply(split_number_from_chars).apply(pd.Series)
melted_df_24[['number', 'currency']] = melted_df_24['currency'].apply(split_number_from_chars).apply(pd.Series)

# Dzielenie wartości poprzez wsłczynnik zdefiniowany dla waluty
melted_df_23['value'] = (melted_df_23['value'].str.replace(',', '.').astype(float) / melted_df_23['number']).round(6)
melted_df_24['value'] = (melted_df_24['value'].str.replace(',', '.').astype(float)/ melted_df_24['number']).round(6)

# Usnięcie kolumny 'number' po przeliczeniu
melted_df_23 = melted_df_23.drop(columns=['number'])
melted_df_24 = melted_df_24.drop(columns=['number'])

# # Konwersja do orginalnego zapisu 
# melted_df_23['value'] = melted_df_23['value'].astype(str).str.replace('.', ',')
# melted_df_24['value'] = melted_df_24['value'].astype(str).str.replace('.', ',')

# Zapis 2023, 2024 i połączonych  danych do plików CSV
output_file_23 = 'reshaped_data_23.csv'
melted_df_23.to_csv(output_file_23, index=False, sep=';', encoding='latin1')
output_file_24 = 'reshaped_data_24.csv'
melted_df_24.to_csv(output_file_24, index=False, sep=';', encoding='latin1')

# Połączenie tabel
melted_df = pd.concat([melted_df_23, melted_df_24])
melted_df['data'] = pd.to_datetime(melted_df['data'], format='%Y%m%d')
output_file = 'reshaped_data.csv'
melted_df.to_csv(output_file, index=False, sep=';', encoding='latin1')

print(melted_df)
```


3. Obliczanie (dla każdej z walut): minimalnej i maksymalnej wartości, kwartyli, średniej, odchylenia standardowego.

```{python}

currency_stats = melted_df.groupby('currency').agg(
    min=pd.NamedAgg(column='value', aggfunc='min'), # min
    max=pd.NamedAgg(column='value', aggfunc='max'), # max
    q1=pd.NamedAgg(column='value', aggfunc=lambda x: x.quantile(0.25)),  # 1szy kwartyl
    q3=pd.NamedAgg(column='value', aggfunc=lambda x: x.quantile(0.75)),  # 3ci kwartyl
    median=pd.NamedAgg(column='value', aggfunc='median'), # mediana
    mean=pd.NamedAgg(column='value', aggfunc='mean'), #średnia arytmetyczne
    std=pd.NamedAgg(column='value', aggfunc='std') #odchylenie standardowe
)

print(currency_stats)

```

4.  Wyznaczanie 97% procentowych przedziałów ufności dla walut.

```{python}

def calc_confidence_interval(data, confidence_level=0.97):
  # Calculate sample mean and standard deviation
  mean = data.mean()
  std = data.std()

  # Calculate critical value (t-score) for chosen confidence level
  alpha = 1 - confidence_level  # significance level
  t_crit = stats.t.ppf(1 - alpha / 2, len(data) - 1)  # one-tailed t-distribution

  # Calculate margin of error
  margin_of_error = t_crit * std / np.sqrt(len(data))

  # Calculate confidence interval bounds
  lower_bound = mean - margin_of_error
  upper_bound = mean + margin_of_error

  return lower_bound, upper_bound

# Słownik do przechowywania przedziałów ufności
confidence_intervals = {}

# Iterate through each currency group
for currency_data, group in melted_df.groupby('currency'):
# Calculate confidence interval
  lower_bound, upper_bound = calc_confidence_interval(group['value'])
  confidence_intervals[currency_data] = (lower_bound, upper_bound)
  
confidence_intervals_df = pd.DataFrame(confidence_intervals).T.reset_index()
confidence_intervals_df = confidence_intervals_df.rename(columns={'index': 'currency', 0: 'lower_bound', 1: 'upper_bound'})

# ci_df = pd.DataFrame(columns=['currency', 'lower_bound', 'upper_bound'])
# for currency_data, group in melted_df.groupby('currency'):
#   lower_bound, upper_bound = calc_confidence_interval(group['value'])
#   confidence_intervals[currency_data] = (lower_bound, upper_bound)  # optional for keeping dictionary

# print(ci_df)
```

Wynik przedstawiony w tabeli.

```{python}
print(confidence_intervals_df)
```

5. Przedziały ufności z pkt. 4 przedstawiony na wykresie.

```{python}

# Calculate mean
confidence_intervals_df['mean'] = (confidence_intervals_df['lower_bound'] + confidence_intervals_df['upper_bound']) / 2

# Plotting the confidence intervals
plt.figure(figsize=(9, 4))

filtered_df = confidence_intervals_df[(confidence_intervals_df['mean'] > 5) & (confidence_intervals_df['mean'] < 6)]


#for i, row in filtered_df.iterrows():
    plt.errorbar(row['currency'], row['mean'], yerr=[[row['mean'] - row['lower_bound']], [row['upper_bound'] - row['mean']]], fmt='.-', label=f'{row["currency"]} Mean')

#plt.title('Currency Exchange Rates with 97% Confidence Intervals')
plt.xlabel('Currency')
plt.ylabel('Exchange Rate')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()
```

6. Wyznaczanie kolejnych miesięcznych przedziałów ufności dla `EUR`. 

```{python}
# Wybór danych dotyczących EUR
eur_data = data_long[data_long['currency'] == '1EUR']

# Grupowanie danych miesięcznie
eur_monthly = eur_data.groupby(pd.Grouper(key='data', freq='M'))

# Obliczenie przedziałów ufności dla każdego miesiąca
monthly_confidence_intervals = eur_monthly.apply(lambda x: stats.t.interval(0.97, len(x)-1, loc=np.mean(x['value']), scale=stats.sem(x['value'])))
```

Wyniki przedstawione na wykresie. Na wykresie uwzględnione zostały również średnie wartości.

```{python}
# Średnie wartości dla każdego miesiąca
monthly_means = eur_monthly['value'].mean()

# Wykres
plt.figure(figsize=(12, 8))
plt.errorbar(monthly_means.index, monthly_means, yerr=(monthly_confidence_intervals.apply(lambda x: (x[1]-x[0])/2)), fmt='o-', label='Średnia wartość', color='blue')
plt.fill_between(monthly_means.index, monthly_confidence_intervals.apply(lambda x: x[0]), monthly_confidence_intervals.apply(lambda x: x[1]), alpha=0.3, color='gray', label='Przedział ufności (97%)')
plt.xlabel('Data')
plt.ylabel('Wartość')
plt.title('Miesięczne przedziały ufności (97%) dla EUR')
plt.legend()
plt.grid(True)
plt.show()
```

7. Oszacowanie współczynników korelacji dla wszystkich możliwych par walutowych.

```{python}
# Lista unikalnych walut
unique_currencies = data_long['currency'].unique()

# Obliczenie współczynnika korelacji dla każdej pary walutowej
correlation_pairs = []
for i in range(len(unique_currencies)):
    for j in range(i+1, len(unique_currencies)):
        currency1 = unique_currencies[i]
        currency2 = unique_currencies[j]
        pair_data = data_long[data_long['currency'].isin([currency1, currency2])]
        correlation = pair_data.pivot_table(index='data', columns='currency', values='value').corr().iloc[0, 1]
        correlation_pairs.append((currency1, currency2, correlation))
```

Wynik zapisany do tabeli, uporządkowany względem siły korelacji.

```{python}
# Konwersja wyników na ramkę danych
correlation_df = pd.DataFrame(correlation_pairs, columns=['Currency 1', 'Currency 2', 'Correlation'])

# Uporządkowanie według siły korelacji
correlation_df['Absolute Correlation'] = correlation_df['Correlation'].abs()
sorted_correlation_df = correlation_df.sort_values(by='Absolute Correlation', ascending=False)
```

Wyświetlenie 10 pierwszych par.

```{python}
top_10_pairs = sorted_correlation_df.head(10)
print(top_10_pairs)
```